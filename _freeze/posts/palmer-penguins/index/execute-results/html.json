{
  "hash": "370b6743d31338644980056f3b04385f",
  "result": {
    "markdown": "---\ntitle: \"Palmer Penguins\"\ndescription: \"Predicting penguin species using the bill length and depth.\"\nauthor: \"Sean Hoyt\"\ndate: \"4/28/2022\"\ncategories: [R, tidy-tuesday, analysis, classification]\nformat:\n  html:\n    toc: true\n---\n\n\n[Link to Github repository](https://github.com/sdhoyt/palmer-penguins-analysis)\n\n\n\n\n\n# Introduction\n\nThis analysis looks at the Palmer Penguins dataset from the Tidy Tuesday repository. This data contains observations of three penguin species among three islands and contains measurements of the penguin's bill length, depth, flipper length, body mass, and sex. The goal of this analysis is to create a K-nearest neighbors classifier model to predict the penguin species using the bill length and depth.\n\n# Analysis\n\n## Setup\n\nLoad the ncessary libraries and import the dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(scales)\ntheme_set(theme_light())\n\n#tt <- tidytuesdayR::tt_load('2020-07-28')\n#penguins_raw <- tt$penguins\npenguins_raw <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-28/penguins.csv')\n```\n:::\n\n\n## Clean Data\n\nThe penguin data has a few missing observations for bill length and depth, flipper length, and body mass. Based on a consistency found amongst species in the data, the missing values are replaced by the mean for that species.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins <- penguins_raw |> \n  # convert to factors\n  mutate(species = factor(species), island = factor(island), sex = factor(sex)) |> \n  group_by(species) |> \n  # replace missing values with average for species\n  mutate(\n    bill_length_mm = ifelse(is.na(bill_length_mm), mean(bill_length_mm, na.rm=TRUE), bill_length_mm),\n    bill_depth_mm = ifelse(is.na(bill_depth_mm), mean(bill_depth_mm, na.rm=TRUE), bill_depth_mm),\n    flipper_length_mm = ifelse(is.na(flipper_length_mm), mean(flipper_length_mm, na.rm=TRUE), flipper_length_mm), \n    body_mass_g = ifelse(is.na(body_mass_g), mean(body_mass_g, na.rm=TRUE), body_mass_g)\n    ) |> \n  ungroup()\n```\n:::\n\n\n## Split Data\n\nThe penguin data is split into training data (70%) to train the K-Nearest Neighbors classifier and test data (30%) to test the accuracy of the classifier model at using the beak length and depth for predicting the species.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\n# split the data into 70% training and 30% test\npenguin_split<- initial_split(penguins, prop=.7)\npenguin_train <- training(penguin_split)\npenguin_test <- testing(penguin_split)\n```\n:::\n\n\n## Build Model\n\nMeasurements of penguins' bill length and depth show distinct clusters grouped by the penguin's species. Because of the separation in the species clusters, we can build a classifier to predict which species a particular penguin belongs to given its bill depth and length measurements.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_train |> \n  ggplot(aes(bill_length_mm, bill_depth_mm, color=species)) +\n  geom_point() + \n  labs(title = \"Penguin Species Predictors\", x=\"Bill Length (mm)\", y=\"Bill Depth (mm)\", color=\"Species\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nWe will use a K-nearest neighbors classifier to predict the penguin species. We start by initializing the nearest neighbor model and instantiate it to use six neighbors. This instructs the model to construct a decision boundary based on the six closest training observations. This means for any test observation, the model will find the six closest training observations, find the proportion of each species within those closest six, then assign the species with the highest proportion to the test observation.\n\nLower nearest neighbor values have lower bias and higher variance, which can lead to over-fitting of the data. The over-fitting is caused by the model using fewer points to classify the test observation, resulting in a more flexible boundary line that more closely takes the shape of the data it is trained on. Higher nearest neighbor values lead to a less flexible boundary (closer to linear line) with higher bias and lower variance since they consider more points to classify the test observation. This can lead to a decision boundary that does not fit the data as as closely as more flexible boundaries, but has more consistent accuracy between test samples. A nearest neighbor value of six was chosen based on model accuracy results against the test data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create and fit the nearest neighbor classifier\nknn_mod <- nearest_neighbor(\n  mode = \"classification\",\n  neighbors = 6) |> \n  fit(formula = species ~ bill_length_mm + bill_depth_mm, data = penguin_train)\n```\n:::\n\n\n## Make Predictions\n\nUsing the k-nearest neighbors model and the test data, we can predict the penguin species for the bill length and depth observations in the test data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# predict classification for test data and bind predictions to dataframe\nknn_pred <- penguin_test %>%\n  bind_cols(predict(knn_mod, .)) |> \n  mutate(species_pred = .pred_class)\n```\n:::\n\n\n## Evaluate Model\n\nWith the prediction results, we can construct a confusion matrix showing where the model correctly and incorrectly predicted the penguin species.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconf_mat <- knn_pred |> \n  # group by the actual/predicted combinations\n  group_by(species, species_pred) |> \n  # count the number of occurences for each combination\n  summarize(count = n(), .groups=\"drop\") |> \n  # extend the data to ensure each combination is in the data\n  complete(species, species_pred) |> \n  # replace the nas from the complete() function with 0s\n  mutate(count = replace_na(count, 0))\n\n  # plot the confusion matrix\n  ggplot(conf_mat, aes(species, fct_rev(species_pred), fill=count)) + \n  geom_tile(show.legend = FALSE) + \n  geom_text(aes(label = count)) +\n  scale_fill_gradient2(low=\"white\", high=\"orange\") + \n  labs(\n    title = \"Penguin Species Confusion Matrix\", \n    x=\"Actual Species\", \n    y=\"Predicted Species\") +\n  theme(\n    panel.border = element_blank(),\n    panel.grid = element_blank(),\n    axis.ticks = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nA closer look at the metrics show that the classifier was effective at predicting the penguin species, with over 95% for accuracy, precision, recall, and specificity.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmetrics <- accuracy(knn_pred, species, species_pred) |> \n  rbind(precision(knn_pred, species, species_pred)) |> \n  rbind(recall(knn_pred, species, species_pred)) |> \n  rbind(specificity(knn_pred, species, species_pred)) |> \n  transmute(Metric = .metric, Estimate = percent(.estimate, accuracy = 0.1))\n\nknitr::kable(metrics, caption = \"Species prediction metrics\")\n```\n\n::: {.cell-output-display}\nTable: Species prediction metrics\n\n|Metric      |Estimate |\n|:-----------|:--------|\n|accuracy    |97.1%    |\n|precision   |96.6%    |\n|recall      |95.6%    |\n|specificity |98.5%    |\n:::\n:::\n\n\n# Summary\n\nUsing the Palmer Penguins dataset, we were able to use the bill length and depth to predict penguin species. Using a K-nearest neighbors classifier model, penguin species were successfully predicted in the test data with an accuracy of 97.1%, precision of 96.6%, recall of 95.6%, and specificity of 98.5%.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}