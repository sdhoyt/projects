---
title: "Tidy Tuesday: Palmer Penguins"
description: "Predicting penguin species using the bill length and depth."
author: "Sean Hoyt"
date: "4/28/2022"
categories: [R, tidy-tuesday, analysis, classification]
format:
  html:
    toc: true
---

[Link to Github repository](https://github.com/sdhoyt/palmer-penguins-analysis)

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE, error=FALSE)
```

# Introduction

This analysis looks at the Palmer Penguins dataset from the Tidy Tuesday repository. This data contains observations of three penguin species among three islands and contains measurements of the penguin's bill length, depth, flipper length, body mass, and sex. The goal of this analysis is to create a K-nearest neighbors classifier model to predict the penguin species using the bill length and depth.

# Analysis

## Setup

Load the ncessary libraries and import the dataset

```{r}
library(tidytuesdayR)
library(tidyverse)
library(tidymodels)
library(scales)
theme_set(theme_light())

#tt <- tidytuesdayR::tt_load('2020-07-28')
#penguins_raw <- tt$penguins
penguins_raw <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-28/penguins.csv')
```

## Clean Data

The penguin data has a few missing observations for bill length and depth, flipper length, and body mass. Based on a consistency found amongst species in the data, the missing values are replaced by the mean for that species.

```{r}
penguins <- penguins_raw |> 
  # convert to factors
  mutate(species = factor(species), island = factor(island), sex = factor(sex)) |> 
  group_by(species) |> 
  # replace missing values with average for species
  mutate(
    bill_length_mm = ifelse(is.na(bill_length_mm), mean(bill_length_mm, na.rm=TRUE), bill_length_mm),
    bill_depth_mm = ifelse(is.na(bill_depth_mm), mean(bill_depth_mm, na.rm=TRUE), bill_depth_mm),
    flipper_length_mm = ifelse(is.na(flipper_length_mm), mean(flipper_length_mm, na.rm=TRUE), flipper_length_mm), 
    body_mass_g = ifelse(is.na(body_mass_g), mean(body_mass_g, na.rm=TRUE), body_mass_g)
    ) |> 
  ungroup()
```

## Split Data

The penguin data is split into training data (70%) to train the K-Nearest Neighbors classifier and test data (30%) to test the accuracy of the classifier model at using the beak length and depth for predicting the species.

```{r}
set.seed(42)
# split the data into 70% training and 30% test
penguin_split<- initial_split(penguins, prop=.7)
penguin_train <- training(penguin_split)
penguin_test <- testing(penguin_split)
```

## Build Model

Measurements of penguins' bill length and depth show distinct clusters grouped by the penguin's species. Because of the separation in the species clusters, we can build a classifier to predict which species a particular penguin belongs to given its bill depth and length measurements.

```{r}
penguin_train |> 
  ggplot(aes(bill_length_mm, bill_depth_mm, color=species)) +
  geom_point() + 
  labs(title = "Penguin Species Predictors", x="Bill Length (mm)", y="Bill Depth (mm)", color="Species")
```

We will use a K-nearest neighbors classifier to predict the penguin species. We start by initializing the nearest neighbor model and instantiate it to use six neighbors. This instructs the model to construct a decision boundary based on the six closest training observations. This means for any test observation, the model will find the six closest training observations, find the proportion of each species within those closest six, then assign the species with the highest proportion to the test observation.

Lower nearest neighbor values have lower bias and higher variance, which can lead to over-fitting of the data. The over-fitting is caused by the model using fewer points to classify the test observation, resulting in a more flexible boundary line that more closely takes the shape of the data it is trained on. Higher nearest neighbor values lead to a less flexible boundary (closer to linear line) with higher bias and lower variance since they consider more points to classify the test observation. This can lead to a decision boundary that does not fit the data as as closely as more flexible boundaries, but has more consistent accuracy between test samples. A nearest neighbor value of six was chosen based on model accuracy results against the test data.

```{r}
# create and fit the nearest neighbor classifier
knn_mod <- nearest_neighbor(
  mode = "classification",
  neighbors = 6) |> 
  fit(formula = species ~ bill_length_mm + bill_depth_mm, data = penguin_train)
```

## Make Predictions

Using the k-nearest neighbors model and the test data, we can predict the penguin species for the bill length and depth observations in the test data.

```{r}
# predict classification for test data and bind predictions to dataframe
knn_pred <- penguin_test %>%
  bind_cols(predict(knn_mod, .)) |> 
  mutate(species_pred = .pred_class)
```

## Evaluate Model

With the prediction results, we can construct a confusion matrix showing where the model correctly and incorrectly predicted the penguin species.

```{r}
conf_mat <- knn_pred |> 
  # group by the actual/predicted combinations
  group_by(species, species_pred) |> 
  # count the number of occurences for each combination
  summarize(count = n(), .groups="drop") |> 
  # extend the data to ensure each combination is in the data
  complete(species, species_pred) |> 
  # replace the nas from the complete() function with 0s
  mutate(count = replace_na(count, 0))

  # plot the confusion matrix
  ggplot(conf_mat, aes(species, fct_rev(species_pred), fill=count)) + 
  geom_tile(show.legend = FALSE) + 
  geom_text(aes(label = count)) +
  scale_fill_gradient2(low="white", high="orange") + 
  labs(
    title = "Penguin Species Confusion Matrix", 
    x="Actual Species", 
    y="Predicted Species") +
  theme(
    panel.border = element_blank(),
    panel.grid = element_blank(),
    axis.ticks = element_blank()
  )
```

A closer look at the metrics show that the classifier was effective at predicting the penguin species, with over 95% for accuracy, precision, recall, and specificity.

```{r}
metrics <- accuracy(knn_pred, species, species_pred) |> 
  rbind(precision(knn_pred, species, species_pred)) |> 
  rbind(recall(knn_pred, species, species_pred)) |> 
  rbind(specificity(knn_pred, species, species_pred)) |> 
  transmute(Metric = .metric, Estimate = percent(.estimate, accuracy = 0.1))

knitr::kable(metrics, caption = "Species prediction metrics")
```

# Summary

Using the Palmer Penguins dataset, we were able to use the bill length and depth to predict penguin species. Using a K-nearest neighbors classifier model, penguin species were successfully predicted in the test data with an accuracy of `r metrics$Estimate[1]`, precision of `r metrics$Estimate[2]`, recall of `r metrics$Estimate[3]`, and specificity of `r metrics$Estimate[4]`.
